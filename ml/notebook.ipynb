{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49c65d6b-b2ff-42a4-a926-98d975b898a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 14:31:07.058207: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-23 14:31:07.058237: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-23 14:31:07.059192: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-23 14:31:07.064119: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-23 14:31:07.617600: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.api._v2.keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c588fa-87e0-4b1d-9fd3-c451b62b86a4",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af2c385b-9c9b-4ca0-831d-615481ae11ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "65 unique characters\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare dataset\n",
    "path_to_file = keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "text = open(path_to_file, 'r').read()\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "print(f'{vocab}\\n{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc89bba9-0354-45c9-8e66-86e66e69975c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 14:31:24.410353: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-23 14:31:24.425465: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-23 14:31:24.425662: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-23 14:31:24.428427: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-23 14:31:24.429281: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-23 14:31:24.429470: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-23 14:31:24.496930: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-23 14:31:24.497101: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-23 14:31:24.497236: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-23 14:31:24.497357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6299 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# These layers can be called to convert between a tf.RaggedTensor of ascii bytes and \n",
    "# a RaggedTensor with the index of that byte in the sorted vocab set.\n",
    "ids_from_chars = keras.layers.StringLookup(vocabulary=vocab)\n",
    "chars_from_ids = keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True)\n",
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df9489e-821d-41d9-ae39-68d2141b0ccf",
   "metadata": {},
   "source": [
    "# Create training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6910e03e-a055-43ab-9adb-1bc7e5e49e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1D tensor that holds the index of each unique character.\n",
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, \"UTF-8\"))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38f5ef78-6b5e-4f2c-935b-73cb81dcf2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a01ce2b0-8c7c-4ae6-aa9e-e5df18f2f017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'F', shape=(), dtype=string)\n",
      "tf.Tensor(b'i', shape=(), dtype=string)\n",
      "tf.Tensor(b'r', shape=(), dtype=string)\n",
      "tf.Tensor(b's', shape=(), dtype=string)\n",
      "tf.Tensor(b't', shape=(), dtype=string)\n",
      "tf.Tensor(b' ', shape=(), dtype=string)\n",
      "tf.Tensor(b'C', shape=(), dtype=string)\n",
      "tf.Tensor(b'i', shape=(), dtype=string)\n",
      "tf.Tensor(b't', shape=(), dtype=string)\n",
      "tf.Tensor(b'i', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for id in ids_dataset.take(10):\n",
    "    print(chars_from_ids(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e434b5-987a-49f5-9e12-0806c4254cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 100\n",
    "# The +1 is since the first 100 chars are used to predict the next, and to do that we are \n",
    "# shifting the sequence in `split_input_target`.\n",
    "sequences = ids_dataset.batch(seq_len + 1, drop_remainder=True)\n",
    "\n",
    "def split_input_target(seq):\n",
    "    # (input sequence, target sequence)\n",
    "    return seq[:-1], seq[1:]\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14c4f2d9-b766-4c0d-ba18-7c8f726c3268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2d9b663-b9c8-4ba6-91df-7b0e7d424313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(64, 100), dtype=int64, numpy=\n",
      "array([[44,  2, 48, ..., 33, 22, 28],\n",
      "       [47, 48, 58, ..., 58, 47, 52],\n",
      "       [51, 51,  2, ..., 40, 58,  2],\n",
      "       ...,\n",
      "       [46, 48, 61, ...,  7,  1, 14],\n",
      "       [44,  7,  1, ..., 54, 45,  2],\n",
      "       [48, 44, 57, ..., 53, 43,  2]])>, <tf.Tensor: shape=(64, 100), dtype=int64, numpy=\n",
      "array([[ 2, 48, 58, ..., 22, 28, 11],\n",
      "       [48, 58,  2, ..., 47, 52, 44],\n",
      "       [51,  2, 59, ..., 58,  2, 48],\n",
      "       ...,\n",
      "       [48, 61, 44, ...,  1, 14, 53],\n",
      "       [ 7,  1, 14, ..., 45,  2, 41],\n",
      "       [44, 57, 58, ..., 43,  2, 42]])>)\n",
      "(<tf.Tensor: shape=(64, 100), dtype=int64, numpy=\n",
      "array([[20, 57, 40, ..., 22, 28, 11],\n",
      "       [44, 57,  2, ..., 40, 43,  2],\n",
      "       [40, 43, 44, ..., 45, 48, 46],\n",
      "       ...,\n",
      "       [48, 58,  2, ...,  2, 51, 48],\n",
      "       [ 2, 40, 51, ..., 64,  2, 53],\n",
      "       [44, 53,  2, ..., 44, 57, 43]])>, <tf.Tensor: shape=(64, 100), dtype=int64, numpy=\n",
      "array([[57, 40, 52, ..., 28, 11,  1],\n",
      "       [57,  2, 42, ..., 43,  2, 54],\n",
      "       [43, 44,  2, ..., 48, 46, 47],\n",
      "       ...,\n",
      "       [58,  2, 57, ..., 51, 48, 50],\n",
      "       [40, 51, 51, ...,  2, 53, 54],\n",
      "       [53,  2, 40, ..., 57, 43, 11]])>)\n"
     ]
    }
   ],
   "source": [
    "for sample in dataset.take(2):\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee410d-7a83-46a2-b191-899a8845a2fb",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c42f6192-7ceb-4cfb-9ebf-7589450e4559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3597e28c-76bc-441d-9dd3-973d73fd802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(vocab_size=len(ids_from_chars.get_vocabulary()), \n",
    "              embedding_dim=256, \n",
    "              rnn_units=390)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec4b3986-db31-41d9-8134-5d8e8a719a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b011496-aa8d-4f4b-9b32-7fdf9909d12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 66)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  16896     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  758160    \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  25806     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 800862 (3.06 MB)\n",
      "Trainable params: 800862 (3.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 15:47:40.664351: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in dataset.take(1):\n",
    "    example_predictions = model(input_batch)[0]\n",
    "    print(example_predictions.shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c43e99e-748b-4581-a320-b84deb313c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 100 vectors of probabilities whose size is the vocab size.\n",
    "# This will take those probabilities and use it reduce the probabilities down\n",
    "# to a single character (num_samples=1) in a non deterministic manner.\n",
    "sampled_indices = tf.random.categorical(example_predictions[0], num_samples=1)\n",
    "# Flatten into a 1D tensor.\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82e93f16-7d0f-4f57-9774-a443078e0d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b\"l me 'lord:' I am your goodman.\\n\\nPage:\\nMy husband and my lord, my lord and husband;\\nI am your wife i\"\n",
      "\n",
      "Predictions:\n",
      " b\"zCYyf\\nBvPD3OcuS?WmrrdAne-'Fn;SNQ$$e,G&quTVxDhGon,ZXJxgXYIytNnHTdwjdh\\nf?3G;Tp&\\nrKEiD:zL.zi!kFBzuSeoi.\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_batch[0]).numpy(), end=\"\\n\"*2)\n",
    "print(\"Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1015e56-7ccc-4c22-82c8-e4fb81c82cb9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11585b10-9324-452f-83fa-3b9005b3fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7854adcf-43ed-4b35-b0c4-faf74743e15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 15:47:55.040663: I external/local_xla/xla/service/service.cc:168] XLA service 0x7e848c7ac980 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-23 15:47:55.040687: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Ti, Compute Capability 8.6\n",
      "2024-01-23 15:47:55.047174: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1706050075.104063   55833 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 3s 10ms/step - loss: 5.4138 - output_1_loss: 2.7069 - output_2_loss: 2.7069\n",
      "Epoch 2/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 4.1311 - output_1_loss: 2.0655 - output_2_loss: 2.0655\n",
      "Epoch 3/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 3.6317 - output_1_loss: 1.8159 - output_2_loss: 1.8159\n",
      "Epoch 4/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 3.3277 - output_1_loss: 1.6639 - output_2_loss: 1.6639\n",
      "Epoch 5/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 3.1347 - output_1_loss: 1.5673 - output_2_loss: 1.5673\n",
      "Epoch 6/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 3.0053 - output_1_loss: 1.5026 - output_2_loss: 1.5026\n",
      "Epoch 7/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.9095 - output_1_loss: 1.4548 - output_2_loss: 1.4548\n",
      "Epoch 8/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.8375 - output_1_loss: 1.4188 - output_2_loss: 1.4188\n",
      "Epoch 9/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.7797 - output_1_loss: 1.3899 - output_2_loss: 1.3899\n",
      "Epoch 10/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.7310 - output_1_loss: 1.3655 - output_2_loss: 1.3655\n",
      "Epoch 11/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.6887 - output_1_loss: 1.3443 - output_2_loss: 1.3443\n",
      "Epoch 12/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.6517 - output_1_loss: 1.3258 - output_2_loss: 1.3258\n",
      "Epoch 13/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.6180 - output_1_loss: 1.3090 - output_2_loss: 1.3090\n",
      "Epoch 14/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.5878 - output_1_loss: 1.2939 - output_2_loss: 1.2939\n",
      "Epoch 15/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.5585 - output_1_loss: 1.2792 - output_2_loss: 1.2792\n",
      "Epoch 16/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.5323 - output_1_loss: 1.2662 - output_2_loss: 1.2662\n",
      "Epoch 17/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.5083 - output_1_loss: 1.2541 - output_2_loss: 1.2541\n",
      "Epoch 18/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.4833 - output_1_loss: 1.2416 - output_2_loss: 1.2416\n",
      "Epoch 19/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.4598 - output_1_loss: 1.2299 - output_2_loss: 1.2299\n",
      "Epoch 20/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.4376 - output_1_loss: 1.2188 - output_2_loss: 1.2188\n",
      "Epoch 21/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.4156 - output_1_loss: 1.2078 - output_2_loss: 1.2078\n",
      "Epoch 22/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.3949 - output_1_loss: 1.1974 - output_2_loss: 1.1974\n",
      "Epoch 23/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.3750 - output_1_loss: 1.1875 - output_2_loss: 1.1875\n",
      "Epoch 24/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.3543 - output_1_loss: 1.1771 - output_2_loss: 1.1771\n",
      "Epoch 25/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.3351 - output_1_loss: 1.1676 - output_2_loss: 1.1676\n",
      "Epoch 26/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.3146 - output_1_loss: 1.1573 - output_2_loss: 1.1573\n",
      "Epoch 27/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.2959 - output_1_loss: 1.1479 - output_2_loss: 1.1479\n",
      "Epoch 28/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.2766 - output_1_loss: 1.1383 - output_2_loss: 1.1383\n",
      "Epoch 29/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.2572 - output_1_loss: 1.1286 - output_2_loss: 1.1286\n",
      "Epoch 30/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.2388 - output_1_loss: 1.1194 - output_2_loss: 1.1194\n",
      "Epoch 31/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.2218 - output_1_loss: 1.1109 - output_2_loss: 1.1109\n",
      "Epoch 32/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.2038 - output_1_loss: 1.1019 - output_2_loss: 1.1019\n",
      "Epoch 33/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.1853 - output_1_loss: 1.0926 - output_2_loss: 1.0926\n",
      "Epoch 34/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.1697 - output_1_loss: 1.0848 - output_2_loss: 1.0848\n",
      "Epoch 35/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.1526 - output_1_loss: 1.0763 - output_2_loss: 1.0763\n",
      "Epoch 36/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.1366 - output_1_loss: 1.0683 - output_2_loss: 1.0683\n",
      "Epoch 37/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.1207 - output_1_loss: 1.0604 - output_2_loss: 1.0604\n",
      "Epoch 38/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.1055 - output_1_loss: 1.0528 - output_2_loss: 1.0528\n",
      "Epoch 39/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.0901 - output_1_loss: 1.0451 - output_2_loss: 1.0451\n",
      "Epoch 40/40\n",
      "172/172 [==============================] - 2s 8ms/step - loss: 2.0748 - output_1_loss: 1.0374 - output_2_loss: 1.0374\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93d830b2-d738-4a8e-b322-3b4ad69da3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'model/dense/kernel:0' shape=(390, 66) dtype=float32, numpy=\n",
       " array([[ 0.11816978, -0.1419592 , -0.07697159, ...,  0.06681882,\n",
       "          0.2614433 ,  0.07730259],\n",
       "        [ 0.02948111, -0.05916449, -0.05198721, ..., -0.08228326,\n",
       "          0.04981517,  0.08267373],\n",
       "        [-0.21526046, -0.0726506 ,  0.00601496, ..., -0.2630161 ,\n",
       "          0.13773723, -0.03098733],\n",
       "        ...,\n",
       "        [ 0.06931859, -0.12202737,  0.13026004, ...,  0.01352862,\n",
       "         -0.19231924,  0.11476504],\n",
       "        [ 0.08553015,  0.17649162,  0.20328814, ...,  0.06267913,\n",
       "          0.30794084,  0.23224291],\n",
       "        [ 0.2002783 , -0.10430484, -0.11017384, ..., -0.00919844,\n",
       "          0.16536172,  0.00916799]], dtype=float32)>,\n",
       " <tf.Variable 'model/dense/bias:0' shape=(66,) dtype=float32, numpy=\n",
       " array([-0.07783867,  0.04700964,  0.01234785,  0.0029173 , -0.08788863,\n",
       "        -0.09699911,  0.08821861, -0.02677115, -0.12356291, -0.04901608,\n",
       "        -0.11843719,  0.03154459, -0.10860135, -0.07468491, -0.03329957,\n",
       "        -0.05755805, -0.09634125, -0.10030784,  0.01789696, -0.03431505,\n",
       "        -0.0785882 , -0.01082918,  0.03406868, -0.10727018, -0.03859717,\n",
       "        -0.03913213, -0.0561174 ,  0.01237729,  0.00503992, -0.08122696,\n",
       "        -0.08782803, -0.04050549, -0.01505292,  0.00506364,  0.00199441,\n",
       "        -0.07717282, -0.07371604, -0.09719842, -0.07702149, -0.09277825,\n",
       "         0.04528946, -0.03742582,  0.02051863,  0.0096319 ,  0.01898768,\n",
       "         0.06296155, -0.02746622,  0.0300769 ,  0.045348  , -0.09646998,\n",
       "        -0.00313703,  0.07057624,  0.08394124,  0.01271339,  0.04526632,\n",
       "        -0.03931019, -0.10633823,  0.02426598,  0.08015396,  0.00946806,\n",
       "         0.03566488, -0.01624491,  0.02020797, -0.13475569, -0.00760351,\n",
       "        -0.10062224], dtype=float32)>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dense.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6ed48a4-3027-426e-863e-52f631ae2c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17e15c8c-c6c2-456f-99dc-5cbea0030310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"model/dense/BiasAdd:0\", shape=(None, None, 66), dtype=float32)\n",
      "Tensor(\"truediv:0\", shape=(None, 66), dtype=float32)\n",
      "Tensor(\"model/dense/BiasAdd:0\", shape=(1, None, 66), dtype=float32)\n",
      "Tensor(\"truediv:0\", shape=(1, 66), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "states=None\n",
    "next_char = tf.constant([\"ROMEO:\"])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model.generate_a_char(next_char, states=states)\n",
    "    result.append(next_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60d33edf-ea48-4bf4-9a21-43700a060dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:HENRY OF YORK:\n",
      "Ay, marry! now, sir, now, then, to jest,\n",
      "For thou art spite a great day: thou dost follow\n",
      "In the wisest unkindness to the culling\n",
      "When it in't it in the god.\n",
      "\n",
      "BRAKENBURY:\n",
      "Yea, mourn of heaven keep what I were at home?\n",
      "\n",
      "MERCUTIO:\n",
      "And vow, cilit is mine arm, and speak aboard.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Why, bear's jottle good!\n",
      "This was, heaven and his wrong's faither?\n",
      "\n",
      "AUFIDIUS:\n",
      "I cannot keep the garden;\n",
      "There still believe it, how to be with him,\n",
      "As mine, in plain'd mercy does with one three new\n",
      "Marvellous large for thy letters that All his afface.\n",
      "\n",
      "ISABELLA:\n",
      "Even you, lady, were I know.\n",
      "We have seen.\n",
      "\n",
      "LUCII:\n",
      "Here in 'sale.'\n",
      "\n",
      "DUKE OF YORK:\n",
      "How did you speak? how sway with mind\n",
      "Time proud of her heart to me day.\n",
      "\n",
      "BADWAY:\n",
      "I'll yield thee my wrapped here and there part a fount\n",
      "Of conduction, remorse, use your highness, wherein deceived\n",
      "As we will find, and emprimed:\n",
      "In once in Rome,\n",
      "And the loath have given to revels at the citizens\n",
      "Despear'd to do with it yours, our loving liege.\n",
      "\n",
      "BU\n"
     ]
    }
   ],
   "source": [
    "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cf1fbe8-78aa-46d2-be52-de37847ceeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <model.OneStep object at 0x7b0891a26710>, because it is not built.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "Tensor(\"model/dense/BiasAdd:0\", shape=(None, None, 66), dtype=float32)\n",
      "Tensor(\"truediv:0\", shape=(None, 66), dtype=float32)\n",
      "Tensor(\"model/dense/BiasAdd:0\", shape=(1, None, 66), dtype=float32)\n",
      "Tensor(\"truediv:0\", shape=(1, 66), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: one_step/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(one_step_model, \"one_step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98b821c6-29c8-4de3-967d-e4197aada4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc536850-fbd6-4556-8b42-7b4f7725b84e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
